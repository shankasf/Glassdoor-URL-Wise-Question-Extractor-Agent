# Glassdoor URL Wise Question Extractor Agent

A comprehensive web scraper designed to extract interview questions and experiences from any Glassdoor interview page, with Cloudflare bypass capabilities and automatic DOCX generation.

## Project Structure

```
tesla_scraper/
â”œâ”€â”€ code/                           # Source code
â”‚   â”œâ”€â”€ enhanced_tesla_scraper.py   # Original Tesla scraper
â”‚   â”œâ”€â”€ smart_qa_extractor.py      # Smart Q&A extraction from JSON
â”‚   â”œâ”€â”€ docx_generator.py          # DOCX file generation
â”‚   â”œâ”€â”€ universal_interview_scraper.py # Universal scraper for any link
â”‚   â””â”€â”€ scrape_any_link.py         # Command-line interface
â”œâ”€â”€ scraped_data/                   # Output data folder
â”‚   â”œâ”€â”€ Tesla/                     # Company-specific folders
â”‚   â”œâ”€â”€ Google/                    # Company-specific folders
â”‚   â”œâ”€â”€ Microsoft/                 # Company-specific folders
â”‚   â””â”€â”€ *.html                     # Raw HTML for debugging
â”œâ”€â”€ logs/                          # Log files
â”œâ”€â”€ venv/                          # Virtual environment
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ interactive_scraper.py         # Interactive mode (recommended)
â”œâ”€â”€ scrape_input.py                # Simple input mode
â”œâ”€â”€ run_scraper.py                 # Command line mode
â””â”€â”€ README.md                      # This file
```

## Features

- **ğŸŒ Universal Scraping**: Works with any Glassdoor interview URL
- **ğŸ›¡ï¸ Cloudflare Bypass**: Uses undetected-chromedriver to bypass protection
- **ğŸ“ Smart Q&A Extraction**: Intelligently extracts questions and answers from interview experiences
- **ğŸ“„ DOCX Generation**: Creates beautifully formatted Word documents
- **ğŸ“Š Multiple Formats**: Saves data in JSON, CSV, and DOCX formats
- **ğŸ” Comprehensive Logging**: Detailed logging for debugging and monitoring
- **ğŸ“ Organized Output**: Clean project structure with dedicated folders

## Installation

1. Create and activate virtual environment:
```bash
python -m venv venv
.\venv\Scripts\Activate.ps1
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

## Usage

### ğŸ¯ Interactive Mode (Recommended)
```bash
python interactive_scraper.py
```
- Interactive menu with options
- URL validation and examples
- Easy to use for beginners

### ğŸ“ Simple Input Mode
```bash
python scrape_input.py
```
- Prompts for URL input
- Validates URL format
- Quick and simple

### ğŸš€ Command Line Mode
```bash
python run_scraper.py "https://www.glassdoor.com/Interview/Tesla-Software-Engineer-Interview-Questions-EI_IE43129.0,5_KO6,23.htm"
```

### Advanced Usage
```bash
# Basic scraping
python code/scrape_any_link.py "https://www.glassdoor.com/Interview/Company-Position-Interview-Questions-EI_IE12345.0,5_KO6,23.htm"

# With custom output prefix
python code/scrape_any_link.py "https://www.glassdoor.com/Interview/Google-Software-Engineer-Interview-Questions-EI_IE9079.0,6_KO7,20.htm" --output google_swe

# Generate DOCX from existing JSON
python code/generate_docx.py
```

## Output

The scraper will create **company-specific folders** for organized data storage:

### ğŸ“ Folder Structure
```
scraped_data/
â”œâ”€â”€ Tesla/                          # Company-specific folder
â”‚   â”œâ”€â”€ interview_data_*.json      # Complete interview data
â”‚   â””â”€â”€ interview_questions_*.docx # Formatted Q&A document
â”œâ”€â”€ Google/                         # Company-specific folder
â”‚   â”œâ”€â”€ interview_data_*.json      # Complete interview data
â”‚   â””â”€â”€ interview_questions_*.docx # Formatted Q&A document
â”œâ”€â”€ Microsoft/                      # Company-specific folder
â”‚   â”œâ”€â”€ interview_data_*.json      # Complete interview data
â”‚   â””â”€â”€ interview_questions_*.docx # Formatted Q&A document
â””â”€â”€ *.html                         # Raw HTML for debugging
```

### ğŸ“Š Files Generated
- **JSON Files**: Complete interview data with metadata
- **DOCX Files**: Formatted questions and answers documents
- **HTML Files**: Raw HTML for debugging (in main folder)
- **Logs**: Detailed execution logs in `logs/` folder

## DOCX Document Features

The generated DOCX files include:
- **ğŸ“‹ Table of Contents** - Quick navigation
- **â“ Q&A Sections** - Formatted questions and answers
- **ğŸ“Š Metadata** - Difficulty, outcome, location, date
- **ğŸ“ˆ Summary Statistics** - Interview statistics and distributions
- **ğŸ¨ Professional Formatting** - Clean, readable layout

## Supported URLs

Any Glassdoor interview URL in the format:
```
https://www.glassdoor.com/Interview/[Company]-[Position]-Interview-Questions-EI_IE[ID].[X],[Y]_KO[Z],[W].htm
```

Examples:
- Tesla Software Engineer: `https://www.glassdoor.com/Interview/Tesla-Software-Engineer-Interview-Questions-EI_IE43129.0,5_KO6,23.htm`
- Google Software Engineer: `https://www.glassdoor.com/Interview/Google-Software-Engineer-Interview-Questions-EI_IE9079.0,6_KO7,20.htm`
- Microsoft Data Scientist: `https://www.glassdoor.com/Interview/Microsoft-Data-Scientist-Interview-Questions-EI_IE1651.0,9_KO10,24.htm`

## Dependencies

- undetected-chromedriver
- selenium
- beautifulsoup4
- requests
- pandas
- lxml
- python-docx

## Examples

### Scrape Tesla Interviews
```bash
python run_scraper.py "https://www.glassdoor.com/Interview/Tesla-Software-Engineer-Interview-Questions-EI_IE43129.0,5_KO6,23.htm"
```

### Scrape Google Interviews
```bash
python run_scraper.py "https://www.glassdoor.com/Interview/Google-Software-Engineer-Interview-Questions-EI_IE9079.0,6_KO7,20.htm"
```

### Generate DOCX from Existing Data
```bash
python code/generate_docx.py
```

## Notes

- The scraper automatically handles Cloudflare challenges
- Data is saved in organized folders for easy access
- Comprehensive logging helps with debugging
- Respects website terms of service and implements delays
- Generated DOCX files are ready for sharing and printing


